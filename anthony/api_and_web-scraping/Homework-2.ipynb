{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Homework 2\"\n",
        "author: \"PSTAT 134/234\"\n",
        "format: pdf\n",
        "editor: visual\n",
        "---"
      ],
      "id": "be4ffd27"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Homework 2\n",
        "\n",
        "[Names of Collaborators (if any):]{.underline} William Mahnke\n",
        "\n",
        "### Part One: Analyzing the Weather\n",
        "\n",
        "In this section, you will gain more practice working with public APIs, this time using a public weather API, [WeatherAPI](https://www.weatherapi.com/). The first thing you'll need to access the API is an API key. You can sign up for a key here: <https://www.weatherapi.com/signup.aspx>\n",
        "\n",
        "#### Exercise 1\n",
        "\n",
        "Use the <http://api.weatherapi.com/v1/current.json> URL to access the API and obtain real-time weather data. Note that you will want to specify three query parameters, at least -- `key`, which should be set to your individual API key, `q`, which should equal the city name of a specified location -- for example `q = \"Isla Vista\"` -- and `aqi`, which indicates whether you want to obtain air quality data (`\"yes\"` or `\"no\"`).\n",
        "\n",
        "Obtain current real-time weather data for **fifty randomly-selected cities**. I have saved a data file containing the names of fifty cities to `/data/cities.csv`. This ensures that you are all working with the same locations (although your results will still differ, depending on when you obtain the data).\n"
      ],
      "id": "d9cb4a17"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# !pip install jupyter\n",
        "# !pip install scikit-learn\n",
        "# !pip install pandas\n",
        "# !pip install statsmodels\n",
        "# !pip install matplotlib\n",
        "# !pip install seaborn\n",
        "# !pip install flask\n",
        "# !pip install requests\n",
        "# !pip install bs4\n",
        "import numpy as np\n",
        "import sklearn as sk\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from flask import Flask, render_template, request  # Import Flask and related modules for web handling\n",
        "import requests  # Import requests library to make HTTP requests\n",
        "from bs4 import BeautifulSoup # for webscraping\n",
        "\n",
        "key = 'dd37f2e2fc62452a904195229241410'\n",
        "cities = pd.read_csv('~/Desktop/Projects/PSTAT 134/homework-2-134-234/data/cities.csv')\n",
        "aqi = \"yes\""
      ],
      "id": "1450ff38",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Exercise 2\n",
        "\n",
        "Write code in R or Python (your choice) to extract and store the following data for each location:\n",
        "\n",
        "-   City name\n",
        "\n",
        "-   Country\n",
        "\n",
        "-   Whether or not it is currently daytime there\n",
        "\n",
        "-   Temperature (in Fahrenheit)\n",
        "\n",
        "-   Humidity\n",
        "\n",
        "-   Weather description (`condition` text; for example, \"Mist\", \"Clear\", etc.)\n",
        "\n",
        "-   Wind speed (in miles per hour)\n",
        "\n",
        "-   Precipitation (in millimeters)\n",
        "\n",
        "-   US EPA air quality index (ranges from $1$ to $6$, representing the 6 categories of air quality: <https://www.airnow.gov/aqi/aqi-basics/>)\n"
      ],
      "id": "5a656f74"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Function to get current weather data from WeatherAPI\n",
        "def get_current_weather(key, city, aqi):\n",
        "    # Construct the API URL with the provided API key and location\n",
        "    url = f\"http://api.weatherapi.com/v1/current.json?key={key}&q={city}&aqi={aqi}\"\n",
        "    \n",
        "    # Send a GET request to the API\n",
        "    response = requests.get(url)\n",
        "    \n",
        "    # Check if the response was successful\n",
        "    if response.status_code == 200:\n",
        "        # Return the JSON data if the request was successful\n",
        "        return response.json()\n",
        "    else:\n",
        "        # Return None if there was an error\n",
        "        return None"
      ],
      "id": "7f4efbe7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "for i in range(len(cities)):\n",
        "  weather_data = get_current_weather(key, cities['names'][i], aqi)\n",
        "  \n",
        "  if weather_data:\n",
        "    cities.loc[i, 'Country'] = weather_data['location']['country']\n",
        "    cities.loc[i, 'Daytime'] = weather_data['current']['is_day']\n",
        "    cities.loc[i, 'Temperature'] = weather_data['current']['temp_f']\n",
        "    cities.loc[i, 'Humidity'] = weather_data['current']['humidity']\n",
        "    cities.loc[i, 'Description'] = weather_data['current']['condition']['text']\n",
        "    cities.loc[i, 'WindSpeed'] = weather_data['current']['wind_mph']\n",
        "    cities.loc[i, 'Precipitation'] = weather_data['current']['precip_mm']\n",
        "    cities.loc[i, 'AirQuality'] = weather_data['current']['air_quality']['us-epa-index']"
      ],
      "id": "91a23352",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Exercise 3\n",
        "\n",
        "Create a scatterplot of temperature vs. humidity. Add a linear regression line to the plot. What are the estimated intercept and slope values for this linear regression? Does there appear to be a significant relationship between temperature and humidity?\n"
      ],
      "id": "4289f2f8"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# in ChatGPT: is there a way to make a scatterplot, then add a line to it?\n",
        "\n",
        "# Create X and y\n",
        "X = cities['Temperature']\n",
        "y = cities['Humidity']\n",
        "X = sm.add_constant(X)  # Add a constant (intercept) to the model\n",
        "\n",
        "# Fit the model\n",
        "model = sm.OLS(y, X).fit()  # Fit the model\n",
        "\n",
        "# Get slope and intercept\n",
        "intercept = model.params[0]\n",
        "slope = model.params[1]\n",
        "y_predictions = model.predict(X)\n",
        "\n",
        "# Plot the regression line\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(cities['Temperature'], y, 'o', color='black') # scatterplot \n",
        "plt.plot(cities['Temperature'], y_predictions, color='red') # line of best fit \n",
        "plt.title('Scatter Plot of Temperature vs. Humidity')\n",
        "plt.xlabel('Temperature (Â°F)')\n",
        "plt.ylabel('Humidity')\n",
        "plt.show()\n",
        "plt.close()\n",
        "\n",
        "print(f\"Y-Intercept: {model.params[0]}\")\n",
        "print(f\"Slopet: {model.params[1]}\")\n",
        "model.summary()"
      ],
      "id": "84172b9e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> There appears to be a negative relationship between temperature (in F) and humidity. As temperature increases, the humidity decreases. We can characterize this change as a 0.4700 decrease in humidity for every 1 degree of Fahrenheit increase.\n",
        "\n",
        "#### Exercise 4\n",
        "\n",
        "Create a bar chart of the EPA air quality index values. What does the distribution of air quality look like? Identify the location(s) with the best air quality and the worst air quality.\n"
      ],
      "id": "426527b1"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# in ChatGPT: \"this is my code: plt.figure(figsize=(10, 6)) sns.barplot(data=cities, x='names', y='AirQuality', order = 'AirQuality') plt.title('Air Quality across Cities') plt.ylabel('Air Quality (EPA Index)') plt.xticks(rotation=90, fontsize = 8) plt.tight_layout() plt.show() plt.close(). how could i order it so that its in descending airquality\"\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(data=cities, x='names', y='AirQuality', order = cities.sort_values('AirQuality', ascending=False)['names'])\n",
        "plt.title('Air Quality across Cities')\n",
        "plt.ylabel('Air Quality (EPA Index)')\n",
        "plt.xticks(rotation=90, fontsize = 8)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "id": "b7b01cf2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> 3 cities (Kolkata, Ahvaz, Lucknow) have the highest EPA index of 5 (worst air quality) while 14 cities (Fez, Pyongyang, Saitama, Guayaquil, Daegu, Basra, Quezon City, Havana, Algiers, Quito, Cologne, Mexico City, Kyoto, Capte Town) are tied for the lowest EPA index of 1 (best air quality = good). This means that these 14 locations have an air quality that is satisfactory and air pollution poses little to no risk. On the other hand, memebers of the general public in the 3 cities with unhealthy air quality may expereince health effects. Most cities have an EPA index of 1 or 2 in our dataset.\n",
        "\n",
        "#### Exercise 5\n",
        "\n",
        "Create a bar chart of the current weather description. Which conditions are the most common? Which are the least?\n"
      ],
      "id": "3e2859ed"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# in ChatGPT: \"i have these descriptions column in my cities dataframe. can i convert all of them to all lowercase\"\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.countplot(data=cities, x=cities['Description'].str.lower(), order = cities['Description'].str.lower().value_counts().index)\n",
        "plt.title('Current Weather Descriptions across Cities')\n",
        "plt.ylabel('Count')\n",
        "plt.yticks(range(0, 20))\n",
        "plt.xticks(rotation=90, fontsize = 8)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "id": "bda0d65c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> Partly cloudy is the most frequent weather condition, with 19 cities currently having that weather condition. Rain nearby and light rain are less frequent conditions, only currently occurring in 2 cities each.\n",
        ">\n",
        "> (Because the data had differences in capitalization convention, I converted all descriptions to lowercase for comparison)\n",
        "\n",
        "#### Exercises for 234 Students\n",
        "\n",
        "##### Exercise 6\n",
        "\n",
        "Do you think day vs. night cycles cause a significant difference in temperature? Test this hypothesis using a *t*-test.\n",
        "\n",
        "##### Exercise 7\n",
        "\n",
        "Create a table of the average temperature, humidity, wind speed, and precipitation broken down by weather description.\n",
        "\n",
        "##### Exercise 8\n",
        "\n",
        "Learn how to use the forecast API (<http://api.weatherapi.com/v1/forecast.json>).\n",
        "\n",
        "Determine the chance of rain (in percentage) for Goleta, California tomorrow. *(Note that \"tomorrow\" may vary depending on when you do this assignment; that is fine.)*\n",
        "\n",
        "Based on the percentage you obtained, do you think it will rain in Goleta tomorrow?\n",
        "\n",
        "### Part Two: Scraping Books\n",
        "\n",
        "In this section, you'll practice your web scraping skills by experimenting with a fictional online bookstore located at <https://books.toscrape.com/>. Use the tools that we demonstrate in class to do the following, in either R or Python (your choice):\n",
        "\n",
        "#### Exercise 9\n",
        "\n",
        "Scrape the first 20 results from this site. Create a data frame (or tibble) that stores the following for each book:\n",
        "\n",
        "-   Title\n",
        "\n",
        "-   Price (excluding tax)\n",
        "\n",
        "-   Star rating\n",
        "\n",
        "-   Whether the book is in stock\n"
      ],
      "id": "db4fe612"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "url = 'https://books.toscrape.com'\n",
        "\n",
        "r = requests.get(url)\n",
        "\n",
        "soup = BeautifulSoup(r.content, 'html.parser')"
      ],
      "id": "2eb7a05f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "rows = soup.select('article.product_pod')\n",
        "\n",
        "books = pd.DataFrame()\n",
        "\n",
        "for i, row in enumerate(rows):\n",
        "  books.loc[i, 'Title'] = row.h3.a['title']\n",
        "  books.loc[i, 'Price'] = row.select_one('.product_price .price_color').text\n",
        "  books.loc[i, 'Star rating'] = row.select_one('.star-rating')['class'][1]\n",
        "  books.loc[i, 'Availability'] = row.select_one('.availability').text.strip()"
      ],
      "id": "1b59e13e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Exercise 10\n",
        "\n",
        "Create a histogram of prices for these 20 books. What is the average price?\n"
      ],
      "id": "ff77e552"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "for i in range(len(books['Price'])):\n",
        "  books.loc[i, 'Price'] = pd.to_numeric(books['Price'][i][1:])\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.set(style=\"whitegrid\")\n",
        "sns.histplot(data=books, x='Price')\n",
        "plt.title('Histogram of Prices of Books', fontsize=16)\n",
        "plt.xlabel('Price', fontsize=14)\n",
        "plt.ylabel('Frequency', fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "plt.close()\n",
        "\n",
        "books['Price'].mean()"
      ],
      "id": "e6b7a3f3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> The average price of books is around 38.05 currency.\n",
        "\n",
        "#### Exercise 11\n",
        "\n",
        "Create a bar chart of star rating for these 20 books. Find the book(s) with the highest and lowest star ratings.\n"
      ],
      "id": "301ed3a9"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "sns.set(style=\"whitegrid\")\n",
        "sns.countplot(data=books, x=pd.Categorical(books['Star rating'], categories = ['One', 'Two', 'Three', 'Four', 'Five'], ordered = True))\n",
        "plt.title('Barplot of star ratings', fontsize=16)\n",
        "plt.xlabel('Star Rating', fontsize=14)\n",
        "plt.ylabel('Frequency', fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "plt.close()\n",
        "\n",
        "books[books['Star rating'] == 'One']\n",
        "books[books['Star rating'] == 'Five']"
      ],
      "id": "833aba32",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> *Tipping the Velvet*, *Soumission*, *The Requiem Red, The Black Maria, Olio,* and *Mesarian* have the lowest rating of 1 star. *Sapiens, Set Me Free, Scott Pilgrim's Precious Little Life,* and *Rip it Up and Start Again* have the highest rating of 5 stars.\n",
        "\n",
        "#### Exercises for 234 Students\n",
        "\n",
        "##### Exercise 12\n",
        "\n",
        "Extend your skills; instead of scraping only the first 20 books, scrape the first **two hundred books**.\n",
        "\n",
        "For each book, in addition to the information we stored previously (title, price, star rating, etc.), figure out how to extract the **category** (i.e., Travel, Mystery, Classics, etc.).\n",
        "\n",
        "##### Exercise 13\n",
        "\n",
        "What is the most common category? What is the least common?"
      ],
      "id": "c14f5a06"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "myenv",
      "language": "python",
      "display_name": "myenv"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}