---
title: "Homework 4"
author: "PSTAT 134/234"
format:
  html:
    toc: true
    toc-location: left
    toc-depth: 4
    embed-resources: true
    theme: simplex
editor: visual
---

## Homework 4

**Note: If this is one of your two late homework submissions, please indicate below; also indicate whether it is your first or second late submission.**

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

This homework assignment has you practice working with some text data, doing some natural language processing. I strongly advise using Lab 7 for assistance.

You also may need to use other functions. I encourage you to make use of our textbook(s) and use the Internet to help you solve these problems. You can also work together with your classmates. If you do work together, you should provide the names of those classmates below.

[Names of Collaborators (if any):]{.underline}

### Natural Language Processing

We'll work with the data in `data/spotify-review-data.csv`. This CSV file contains a total of 51,473 rows, each representing a unique user review for the Spotify application. The dataset has two columns:

-   Review: This column contains the text of user reviews, reflecting their experiences, opinions, and feedback on the Spotify app.

-   Sentiment label: This column categorizes each review as either "POSITIVE" or "NEGATIVE" based on its sentiment.

The data comes from this source at Kaggle: <https://www.kaggle.com/datasets/alexandrakim2201/spotify-dataset>

#### Exercise 1

Read the data into R (or Python, whichever you prefer).

Take a look at the distribution of `label`. Are there relatively even numbers of negative and positive reviews in the data set?

#### Exercise 2

Take a random sample of $10,000$ reviews, stratified by `label`. All further exercises will be working with this smaller sample of reviews.

#### Exercise 3

Tokenize the reviews into words.

Remove stop words. (You can use any pre-made list of stop words of your choice.)

Clean the reviews. Remove punctuation and convert the letters to lowercase.

Verify that this process worked correctly.

#### Exercise 4

Create a bar chart of the most commonly-occurring words (not including stop words).

Create bar charts of the most commonly-occurring words, broken down by `label`. What words are more common in positive reviews? What words are more common in negative reviews?

#### Exercise 5

Create a word cloud of the most commonly-occurring words overall, broken down by "positive" or "negative" sentiment (using the Bing sentiment lexicon).

#### Exercise 6

Calculate the tf-idf values for the words in the dataset.

Find the 30 words with the largest tf-idf values.

Find the 30 words with the smallest tf-idf values.

#### Exercise 7

Find the 30 most commonly occuring bigrams.

Create graphs visualizing the networks of bigrams, broken down by `label`. That is, make one graph of the network of bigrams for the positive reviews, and one graph of the network for the negative reviews.

What patterns do you notice?

#### Exercise 8

Using the tokenized **words** and their corresponding tf-idf scores, fit a **linear support vector machine** to predict whether a given review is positive or negative.

-   Split the data using stratified sampling, with 70% training and 30% testing;

-   Drop any columns with zero variance;

-   Fit a linear support vector machine using default values for any hyperparameters;

-   Calculate the model **accuracy** on your testing data.

#### For 234 Students

#### Exercise 9

Using **either** Bag of Words or Word2Vec, extract a matrix of features. (Note: You can reduce the size of the dataset even further by working with a sample of $3,000$ reviews if need be.)

#### Exercise 10

Fit and tune a **logistic regression model, using lasso regularization**. Follow the same procedure as before, with a few changes:

-   Stratified sampling, with a 70/30 split;

-   Drop any columns with zero variance;

-   Tune `penalty`, using the default values;

-   Calculate your best model's **accuracy** on the testing data.
